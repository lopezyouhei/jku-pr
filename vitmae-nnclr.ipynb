{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from lightly.loss import NTXentLoss\n",
    "from lightly.models.modules import (\n",
    "    NNCLRPredictionHead,\n",
    "    NNCLRProjectionHead,\n",
    "    NNMemoryBankModule,\n",
    ")\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data_path = os.path.join(os.getcwd(), \"features_mae_large\")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understand Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50000, 1024])\n"
     ]
    }
   ],
   "source": [
    "test_center_crop = torch.load(data_path + \"mae_l23_cls_test_centercrop.th\")\n",
    "print(test_center_crop.shape)\n",
    "del test_center_crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1281167, 1024])\n"
     ]
    }
   ],
   "source": [
    "train_center_crop = torch.load(data_path + \"mae_l23_cls_train_centercrop.th\")\n",
    "print(train_center_crop.shape)\n",
    "del train_center_crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1281167, 1024])\n"
     ]
    }
   ],
   "source": [
    "v1_seed0 = torch.load(data_path + \"tensors_v1_seed_0.th\")\n",
    "print(v1_seed0.shape)\n",
    "del v1_seed0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1281167, 1024])\n"
     ]
    }
   ],
   "source": [
    "v1_seed2 = torch.load(data_path + \"tensors_v1_seed_2.th\")\n",
    "print(v1_seed2.shape)\n",
    "del v1_seed2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1281167, 1024])\n"
     ]
    }
   ],
   "source": [
    "v1_seed3 = torch.load(data_path + \"tensors_v1_seed_3.th\")\n",
    "print(v1_seed3.shape)\n",
    "del v1_seed3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1281167, 1024])\n"
     ]
    }
   ],
   "source": [
    "v1_seed4 = torch.load(data_path + \"tensors_v1_seed_4.th\")\n",
    "print(v1_seed4.shape)\n",
    "del v1_seed4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1281167, 1024])\n"
     ]
    }
   ],
   "source": [
    "v1_seed5 = torch.load(data_path + \"tensors_v1_seed_5.th\")\n",
    "print(v1_seed5.shape)\n",
    "del v1_seed5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1281167, 1024])\n"
     ]
    }
   ],
   "source": [
    "v1_seed6 = torch.load(data_path + \"tensors_v1_seed_6.th\")\n",
    "print(v1_seed6.shape)\n",
    "del v1_seed6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1281167, 1024])\n"
     ]
    }
   ],
   "source": [
    "v2_seed0 = torch.load(data_path + \"tensors_v2_seed_0.th\")\n",
    "print(v2_seed0.shape)\n",
    "del v2_seed0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1281167, 1024])\n"
     ]
    }
   ],
   "source": [
    "v2_seed1 = torch.load(data_path + \"tensors_v2_seed_1.th\")\n",
    "print(v2_seed1.shape)\n",
    "del v2_seed1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1281167, 1024])\n"
     ]
    }
   ],
   "source": [
    "v2_seed2 = torch.load(data_path + \"tensors_v2_seed_2.th\")\n",
    "print(v2_seed2.shape)\n",
    "del v2_seed2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1281167, 1024])\n"
     ]
    }
   ],
   "source": [
    "v2_seed3 = torch.load(data_path + \"tensors_v2_seed_3.th\")\n",
    "print(v2_seed3.shape)\n",
    "del v2_seed3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1281167, 1024])\n"
     ]
    }
   ],
   "source": [
    "v2_seed4 = torch.load(data_path + \"tensors_v2_seed_4.th\")\n",
    "print(v2_seed4.shape)\n",
    "del v2_seed4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1281167, 1024])\n"
     ]
    }
   ],
   "source": [
    "v2_seed5 = torch.load(data_path + \"tensors_v2_seed_5.th\")\n",
    "print(v2_seed5.shape)\n",
    "del v2_seed5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1281167, 1024])\n"
     ]
    }
   ],
   "source": [
    "v2_seed6 = torch.load(data_path + \"tensors_v2_seed_6.th\")\n",
    "print(v2_seed6.shape)\n",
    "del v2_seed6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50000])\n",
      "torch.Size([1000])\n"
     ]
    }
   ],
   "source": [
    "test_labels = torch.load(data_path + \"test-labels.th\")\n",
    "print(test_labels.shape)\n",
    "print(test_labels.unique().shape)\n",
    "del test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1281167])\n",
      "torch.Size([1000])\n"
     ]
    }
   ],
   "source": [
    "train_labels = torch.load(data_path + \"train-labels.th\")\n",
    "print(train_labels.shape)\n",
    "print(train_labels.unique().shape)\n",
    "del train_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MAEDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, view1_path, view2_path):\n",
    "\n",
    "        self.data1 = torch.load(view1_path)\n",
    "        self.data2 = torch.load(view2_path)\n",
    "        assert self.data1.shape == self.data2.shape, \"view1 and view2 must have the same shape\"\n",
    "        self.length = self.data1.shape[0]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data1[idx], self.data2[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNCLRHead(nn.Module):\n",
    "    def __init__(self, project_hidden_dim, project_output_dim, \n",
    "                 predict_hidden_dim, predict_output_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.projection_head = NNCLRProjectionHead(1024, # input_dim \n",
    "                                                   project_hidden_dim, # hidden_dim \n",
    "                                                   project_output_dim) # output_dim\n",
    "        self.prediction_head = NNCLRPredictionHead(project_output_dim, # input_dim \n",
    "                                                   predict_hidden_dim, # hidden_dim\n",
    "                                                   predict_output_dim) # output_dim\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.projection_head(x)\n",
    "        p = self.prediction_head(z)\n",
    "        z = z.detach()\n",
    "        return z, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 1024\n",
    "LR = 1e-4\n",
    "TEMPERATURE = 0.15\n",
    "QUEUE_SIZE = 65536\n",
    "WEIGHT_DECAY = 1e-5\n",
    "PROJECT_HIDDEN_DIM = 2048\n",
    "PROJECT_OUTPUT_DIM = 256\n",
    "PREDICTION_HIDDEN_DIM = 4096\n",
    "PREDICTION_OUTPUT_DIM = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:/Users/lopez/Projects/jku-pr/features_mae_large/tensors_v1_seed_0.th\n"
     ]
    }
   ],
   "source": [
    "view1_path = os.path.join(data_path, \"tensors_v1_seed_0.th\").replace(\"\\\\\", \"/\")\n",
    "view2_path = os.path.join(data_path, \"tensors_v2_seed_0.th\").replace(\"\\\\\", \"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training\n",
      "epoch: 00, loss: 10.61001\n",
      "epoch: 01, loss: 8.99533\n",
      "epoch: 02, loss: 7.80246\n",
      "epoch: 03, loss: 7.22053\n",
      "epoch: 04, loss: 6.89556\n",
      "epoch: 05, loss: 6.68435\n",
      "epoch: 06, loss: 6.53453\n",
      "epoch: 07, loss: 6.42043\n",
      "epoch: 08, loss: 6.32916\n",
      "epoch: 09, loss: 6.25517\n"
     ]
    }
   ],
   "source": [
    "model = NNCLRHead(PROJECT_HIDDEN_DIM, \n",
    "                  PROJECT_OUTPUT_DIM, \n",
    "                  PREDICTION_HIDDEN_DIM, \n",
    "                  PREDICTION_OUTPUT_DIM)\n",
    "model.to(device)\n",
    "memory_bank = NNMemoryBankModule(size=(QUEUE_SIZE, PREDICTION_OUTPUT_DIM))\n",
    "memory_bank.to(device)\n",
    "criterion = NTXentLoss(temperature=TEMPERATURE, memory_bank_size=(QUEUE_SIZE, PREDICTION_OUTPUT_DIM))\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "dataset = MAEDataset(view1_path, view2_path)\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset, \n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "\n",
    "print(\"Starting Training\")\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0\n",
    "    for x0, x1 in dataloader:\n",
    "        x0, x1 = x0.to(device), x1.to(device)\n",
    "        z0, p0 = model(x0)\n",
    "        z1, p1 = model(x1)\n",
    "        z0 = memory_bank(z0, update=False) # update can be True for z0 xor z1\n",
    "        z1 = memory_bank(z1, update=True)\n",
    "        loss = 0.5 * (criterion(z0, p1) + criterion(z1, p0))\n",
    "        total_loss += loss.detach()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    print(f\"epoch: {epoch:>02}, loss: {avg_loss:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantitative metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jku-pr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
