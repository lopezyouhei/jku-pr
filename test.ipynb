{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\lopez\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from PR.utils import load_yaml\n",
    "from PR.config.class_group import categories\n",
    "from PR.NNCLR.model import NNCLRHead\n",
    "from PR.metrics.metrics_utils import group_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Paths and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = r\"C:\\Users\\lopez\\Projects\\jku-pr\\features_mae_large\"\n",
    "class_to_classid_path = os.path.join(data_path, \"in1k_class_to_classid.yaml\")\n",
    "train_path = os.path.join(data_path, \"mae_l23_cls_train_centercrop.th\")\n",
    "train_labels_path = os.path.join(data_path, \"train-labels.th\")\n",
    "test_path = os.path.join(data_path, \"mae_l23_cls_test_centercrop.th\")\n",
    "test_labels_path = os.path.join(data_path, \"test-labels.th\")\n",
    "\n",
    "class_to_classid = load_yaml(class_to_classid_path)\n",
    "train_data = torch.load(train_path, map_location=device)\n",
    "train_labels = torch.load(train_labels_path, map_location=device)\n",
    "test_data = torch.load(test_path, map_location=device)\n",
    "test_labels = torch.load(test_labels_path, map_location=device)\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=1, shuffle=False)\n",
    "test_dataloader = DataLoader(test_data, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_state_dict = r\"C:\\Users\\lopez\\Projects\\jku-pr\\models\\tensors_v1_seed_0_tensors_v2_seed_0_0_1-0_baseline.pth\"\n",
    "state_dict = torch.load(model_state_dict, map_location=device)\n",
    "\n",
    "model = NNCLRHead()\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_names, category_labels = group_classes(test_labels, categories, class_to_classid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\lopez\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "def check_synset_exists(synset_name):\n",
    "    try:\n",
    "        # attempt to get synset using provided name\n",
    "        syn = wn.synset(synset_name)\n",
    "        return True, syn.definition() # TODO: do we need the 2nd output?\n",
    "    except nltk.corpus.reader.wordnet.WordNetError:\n",
    "        return False, None # TODO: do we need the 2nd output\n",
    "    \n",
    "main_5_categories = {\n",
    "    'animals': 'animal.n.01',   \n",
    "    'vehicles': 'vehicle.n.01', \n",
    "    'household': 'artifact.n.01',\n",
    "    'food': 'food.n.01',\n",
    "    'nature': 'natural_object.n.01'\n",
    "}\n",
    "\n",
    "dog_15_categories = {\n",
    "    'maltese dog': 'maltese_dog.n.01',\n",
    "    'blenheim spaniel': 'blenheim_spaniel.n.01',\n",
    "    'basset': 'basset.n.01',\n",
    "    'norwegian elkhound': 'norwegian_elkhound.n.01',\n",
    "    'giant schnauzer': 'giant_schnauzer.n.01',\n",
    "    'golden retriever': 'golden_retriever.n.01',\n",
    "    'brittany spaniel': 'brittany_spaniel.n.01',\n",
    "    'clumber': 'clumber.n.01',\n",
    "    'welsh springer spaniel': 'welsh_springer_spaniel.n.01',\n",
    "    'groenendael': 'groenendael.n.01',\n",
    "    'kelpie': 'kelpie.n.01',\n",
    "    'shetland sheepdog': 'shetland_sheepdog.n.01',\n",
    "    'doberman': 'doberman.n.01',\n",
    "    'pug': 'pug.n.01',\n",
    "    'chow': 'chow.n.01',\n",
    "}\n",
    "\n",
    "wen_10_categories = {\n",
    "    'bird': 'bird.n.01',\n",
    "    'boat': 'boat.n.01',\n",
    "    'car': 'car.n.01',\n",
    "    'cat': 'cat.n.01',\n",
    "    'dog': 'dog.n.01',\n",
    "    'fruit': 'fruit.n.01',\n",
    "    'fungus': 'fungus.n.01',\n",
    "    'insect': 'insect.n.01',\n",
    "    'monkey': 'monkey.n.01',\n",
    "    'truck': 'truck.n.01',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "for synset_name in wen_10_categories.values():\n",
    "    print(check_synset_exists(synset_name)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jku-pr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
